
# <center> Демонстрация работы языка SQL из Python на примере анализа вакансий на сайте Head Hunter </center>
## Оглавление
1. [Описание проекта](#Описание-проекта)
2. [Описание данных](#Описание-данных)
3. [Зависимости](#Используемые-зависимости)
4. [Установка проекта](#Установка-проекта)
5. [Авторы](#Авторы)
6. [Выводы](Использование-проекта)

## Описание проекта

**SQL**  — это язык структурированных запросов (Structured Query Language), позволяющий хранить, манипулировать и извлекать данные из реляционных баз данных (далее — РБД, БД)..
**SQL позволяет:** 
* получать доступ к данным в системах управления РБД
* описывать данные (их структуру)
* определять данные в БД и управлять ими
* взаимодействовать с другими языками через модули SQL, библиотеки и предваритальные компиляторы
* создавать и удалять БД и таблицы
* создавать представления, хранимые процедуры (stored procedures) и функции в БД
* устанавливать разрешения на доступ к таблицам, процедурам и представлениям

Основные этапы подготовки данных:
* Предварительный анализ данных
* Детальный анализ данных
* Анализ работодателей
* Предметный анализ

**Цель основных этапов подготовки данных** — создать сводную таблицу данных, объединив данные начальных таблиц по ключам, и с применением методов фильтрации и сортировки получить данные для дальнейшего построения модели. Во многих задачах такие преобразования нередко занимают большую часть времени работы над задачей.


**О структуре проекта:**
* [Project_2_ноутбук_шаблон.ipynb](.\Project-1.Ноутбук-шаблон.ipynb) - jupyter-ноутбук, содержащий основной код проекта 


## Описание данных
В этом проекте используются данные с сайта по поиску вакансий HeadHunter. 

Требования состояли в том, чтобы объединить несколько первоначальных таблиц и с помощью запросов SQL такие данные как: "Кол-во вакансий", "Кол-во работодателей", "Кол-во регионов", "Кол-во сфер деятельности", "Данные о зарплатах", "Кол-во вакансий для каждого сочетания рабочего графика и типа трудоустройства", "Требования к опыту", "Кл-во вакансий с учетом ключевых навыков для специалиста DS". 

Исходный датасет представляет собой набор данных с информацией об работодателях, регионах, сферах деятельности, а также данные о заработной плате, опыте работы, городе, желаемом графике работы и т.д.

## Используемые зависимости
* Python (3.9):
    * [psycopg2 (3.1)](https://psycopg.org)
    * [pandas (1.3.4)](https://pandas.pydata.org)
    * [matplotlib (3.4.3)](https://matplotlib.org)
    * [seaborn (0.11.2)](https://seaborn.pydata.org)
    * [requests(2.28.2)](https://pypi.org/project/requests/)
    * [BeautifulSoup(4.8.1)](https://beautiful-soup-4.readthedocs.io/en/latest/#)

## Установка проекта

```
git clone https://github.com/Blef0099/Project_2.git
```

## Авторы

* [Иванов Дмитрий]

## Выводы

Данный проект учит начинающего датасайнтиста правильно подходить к работе с данными: объединять таблицы с помощью языка SQL, применять сортировку и фильтрацию. Это работа требует значительного усердия и внимательности обращения с данными, так как именно от этого этапа будет зависить какие данные мы получим на выходе и как будет работать созданная на базе этих данных модель. 